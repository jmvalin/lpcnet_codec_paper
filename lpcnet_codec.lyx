#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble


\usepackage{INTERSPEECH2019}

\usepackage[pdftex,linkcolor=black,urlcolor=black,citecolor=black,pdfpagemode=None,pdfstartview=FitH,pdfview=FitH,colorlinks=true,pdftitle=LPCNet: Improving Neural Speech Synthesis Through Linear Prediction,pdfauthor=Jean-Marc Valin]{hyperref}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding auto
\fontencoding default
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 0
\use_package cancel 0
\use_package esint 0
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
title{A Real-Time Wideband Neural Vocoder at 1.6 kb/s Using LPCNet}
\end_layout

\begin_layout Plain Layout


\backslash
name{Author Name$^1$, Co-author Name$^2$}
\end_layout

\begin_layout Plain Layout


\backslash
address{   $^1$Author Affiliation
\backslash

\backslash
   $^2$Co-author Affiliation}
\end_layout

\begin_layout Plain Layout


\backslash
email{author@university.edu, coauthor@company.com} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
maketitle
\end_layout

\end_inset

 
\end_layout

\begin_layout Abstract
This is all very abstract
\end_layout

\begin_layout Standard
\noindent

\series bold
Index Terms
\series default
: neural speech synthesis, wideband coding, vocoder, LPCNet, WaveRNN
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Low complexity parametric codecs have existed for a long time
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "atal1971speech,markel1974linear"
literal "false"

\end_inset

, but their quality has always been severely limited.
 While they are generally efficient at modeling the spectral envelope (vocal
 tract response) of the speech using linear prediction, no such simple model
 exists for the excitation.
 Despite some advances
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "griffin1985new,mccree1996,rowe1997"
literal "false"

\end_inset

, modeling the excitation signal has remained a challenge.
\end_layout

\begin_layout Standard
Neural speech synthesis algorithms such as Wavenet
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "van2016wavenet"
literal "false"

\end_inset

 and SampleRNN
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "mehri2016samplernn"
literal "false"

\end_inset

 have recently made it possible to synthesize high quality speech.
 WaveNet and SampleRNN have also be used in 
\begin_inset CommandInset citation
LatexCommand cite
key "kleijn2018wavenet,Garbacea2019,klejsa2018high"
literal "false"

\end_inset

 to synthesize high-quality speech from coded features, with a complexity
 ranging in the tens of GFLOPS.
 This typically makes it impossible to use them in real time without high-end
 hardware (if at all).
 
\end_layout

\begin_layout Standard
In this work, we focus on simpler models, that are can be implemented on
 general-purpose hardware and mobile devices for real-time communication,
 and that work for any speaker using any language.
\end_layout

\begin_layout Section
WaveRNN and LPCNet
\end_layout

\begin_layout Standard
WaveRNN was proposed in
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "kalchbrenner2018efficient"
literal "false"

\end_inset

 as a more computationally efficient alternative to WaveNet.
 Its use of a recurrent neural network (RNN) along with sparse matrices
 makes it possible to achieve real-time synthesis without a GPU.
 More recently, we proposed the LPCNet
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "lpcnet"
literal "false"

\end_inset

 model, which improves on the efficiency of WaveRNN by augmenting the RNN
 with linear prediction.
 
\end_layout

\begin_layout Standard
The LPCNet model is summarized in Fig.
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Overview-of-LPCNet"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 It operates on signals quantized using 256-level 
\begin_inset Formula $\mu$
\end_inset

\SpecialChar nobreakdash
law.
 To avoid audible quantization noise, a pre-emphasis filter 
\begin_inset Formula $E(z)=1-\alpha z^{-1}$
\end_inset

 is used on the input speech (with 
\begin_inset Formula $\alpha=0.85$
\end_inset

) and the inverse de-emphasis filter is applied to the output.
 This shapes the noise in a way that it is not easily noticeable.
 In addition to receiving as input the previously generated speech sample
 
\begin_inset Formula $s_{t-1}$
\end_inset

, LPCNet also receives...
\end_layout

\begin_layout Standard
Like WaveRNN, LPCNet is based on a gated recurrent unit (GRU)
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "cho2014properties"
literal "false"

\end_inset

 layer.
 To reduce the complexity, the recurrent matrices in the main GRU (
\begin_inset Formula $\mathrm{GRU_{A}}$
\end_inset

) are sparse.
 
\end_layout

\begin_layout Standard
The dual_DC layer is defined as 
\begin_inset Formula 
\begin{equation}
\mathrm{dual\_fc}(\mathbf{x})=\mathbf{a}_{1}\circ\tanh\left(\mathbf{W}_{1}\mathbf{x}\right)+\mathbf{a}_{2}\circ\tanh\left(\mathbf{W}_{2}\mathbf{x}\right)\ ,\label{eq:dual_fc}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering{
\end_layout

\end_inset


\begin_inset Graphics
	filename overview.pdf
	width 100col%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Overview of the LPCNet model.
 The frame rate network (yellow) operates on 10\SpecialChar nobreakdash
ms frames and its output
 is held constant through each frame for the sample rate network (blue).
 The 
\emph on
compute prediction
\emph default
 block applies linear prediction to predict the sample at time 
\begin_inset Formula $t$
\end_inset

 from the previous samples.
 Conversions between 
\begin_inset Formula $\mu$
\end_inset

-law and linear are omitted for clarity.
 The de-emphasis filter is applied to the output 
\begin_inset Formula $s_{t}$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:Overview-of-LPCNet"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Features and Quantization
\end_layout

\begin_layout Standard
LPCNet is designed to operate with 10\SpecialChar nobreakdash
ms features.
 To achieve a low bitrate, we use 40\SpecialChar nobreakdash
ms packets, each representing 4
\begin_inset space ~
\end_inset

LPCNet frames.
 Each packet is coded with 64
\begin_inset space ~
\end_inset

bits, allocated as shown in Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Bit-allocation"
plural "false"
caps "false"
noprefix "false"

\end_inset

, for a total bitrate of 1.6
\begin_inset space ~
\end_inset

kb/s (CBR).
 
\end_layout

\begin_layout Standard
LPC computed from the quantized spectrum
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Bit allocation for a 40\SpecialChar nobreakdash
ms frame.
\begin_inset CommandInset label
LatexCommand label
name "tab:Bit-allocation"

\end_inset


\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering{
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="2">
<features tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Parameter
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Bits
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Pitch period
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Pitch modulation
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Pitch gain
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Energy (C0)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Cepstrum VQ (40
\begin_inset space ~
\end_inset

ms)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
30
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Cepstrum delta (20
\begin_inset space ~
\end_inset

ms)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
13
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Cepstrum interpolation (10
\begin_inset space ~
\end_inset

ms)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Total
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Pitch
\end_layout

\begin_layout Standard
Extracting the correct pitch (without period doubling of halving) is very
 important for a vocoder since no residual is coded to make up for prediction
 errors.
 During development, we have observed that unlike traditional vocoders,
 the neural vocoder has some ability to compensate for incorrect pitch values,
 but only up to a point.
 Moreover, that ability is reduced when the cepstrum is quantized.
 
\end_layout

\begin_layout Standard
The pitch search operates on the excitation signal.
 Maximizing the correlation over an entire 40\SpecialChar nobreakdash
ms packet does not produce
 good results because the pitch can vary within that time.
 Instead, we divide each packet in 5\SpecialChar nobreakdash
ms sub-frames, and find the set of pitch
 lags 
\begin_inset Formula $\tau_{i}$
\end_inset

 that maximize the following expression:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
J=\sum_{i}\left[w_{i}r\left(\tau_{i}\right)+\Theta\left(\tau_{i}-\tau_{i-1}\right)\right]\,,
\]

\end_inset

where 
\begin_inset Formula $w_{i}$
\end_inset

 is the ratio of the sub-frame energy over the average energy over the 40\SpecialChar nobreakdash
ms
 packet, 
\begin_inset Formula $\Theta\left(\Delta_{\tau}\right)$
\end_inset

 is a transition penalty, and 
\begin_inset Formula $r\left(\tau_{i}\right)$
\end_inset

 is a modified pitch correlation.
 
\end_layout

\begin_layout Standard
The optimal path can be computed using dynamic programming with a Viterbi
 search.
 Since the entire audio is not available at once, the running values of
 
\begin_inset Formula $J$
\end_inset

 are updated for every sub-frame and the Viterbi backtrack pass is computed
 once per 40\SpecialChar nobreakdash
ms packet, over all 8
\begin_inset space ~
\end_inset

sub-frames.
 While that does not guarantee finding the optimal path, it ensures a consistent
 pitch over the duration of the packet.
 
\end_layout

\begin_layout Standard
The allowed pitch values range from 62.5
\begin_inset space ~
\end_inset

Hz to 500
\begin_inset space ~
\end_inset

Hz.
 The pitch is encoded on a logarithmic scale using 6
\begin_inset space ~
\end_inset

bits, resulting in quantization intervals of 0.57
\begin_inset space ~
\end_inset

semitones.
 
\end_layout

\begin_layout Standard
A linear pitch modulation parameter allows up to 16% variation (2.5
\begin_inset space ~
\end_inset

semitones) between the first and last sub-frame.
 It is encoded with 3 bits representing a 
\begin_inset Formula $\left[-3,3\right]$
\end_inset

 range with the two different codes for 0 (constant modulation), one of
 which also signals that the pitch correlation is less than 0.3 (the modulation
 is zero when the pitch correlation is too small).
 
\end_layout

\begin_layout Subsection
Cepstrum
\end_layout

\begin_layout Standard
The analysis operates on 20\SpecialChar nobreakdash
ms windows with 50% overlap.
 The cepstrum is computed from 18
\begin_inset space ~
\end_inset

Bark-spaced bands following the layout in
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "valin2017hybrid"
literal "false"

\end_inset

.
 Because we pack 4
\begin_inset space ~
\end_inset

cepstral vectors in each packet, we wish to maximize redundancy elimination
 within a packet while limiting dependencies across packets to reduce the
 effect of packet loss.
 For those reasons, we use a quantization scheme inspired from video codec
 B\SpecialChar nobreakdash
frames
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "MPEG1"
literal "false"

\end_inset

, and that limits the error propagation in case of packet loss to a worst
 case of 30
\begin_inset space ~
\end_inset

ms.
 It is illustrated in Fig.
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Prediction-and-quantization"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
Let packet 
\begin_inset Formula $k$
\end_inset

 include cepstral vectors 
\begin_inset Formula $\mathbf{c}_{4k}$
\end_inset

 to 
\begin_inset Formula $\mathbf{c}_{4k+3}$
\end_inset

, we first code all but the first component of 
\begin_inset Formula $\mathbf{c}_{4k+3}$
\end_inset

 independently for each packet using a 3\SpecialChar nobreakdash
stage codebook with 10
\begin_inset space ~
\end_inset

bits for each stage.
 An M-best (survivor) search help reduce the quantization error, but is
 not strictly necessary.
 The first component (C0) of 
\begin_inset Formula $\mathbf{c}_{4k+3}$
\end_inset

 is coded with a uniform 7\SpecialChar nobreakdash
bit scalar quantizer (0.83
\begin_inset space ~
\end_inset

dB resolution).
 From there, vector 
\begin_inset Formula $\mathbf{c}_{4k+1}$
\end_inset

 is predictively coded from both 
\begin_inset Formula $\mathbf{c}_{4k-1}$
\end_inset

 (independently coded in the previous frame) and 
\begin_inset Formula $\mathbf{c}_{4k+3}$
\end_inset

.
 We use a single bit to signal if the prediction is the average (
\begin_inset Formula $\frac{\mathbf{c}_{4k-1}+\mathbf{c}_{4k+3}}{2}$
\end_inset

), or two bits if the prediction is either of 
\begin_inset Formula $\mathbf{c}_{4k-1}$
\end_inset

 or 
\begin_inset Formula $\mathbf{c}_{4k+3}$
\end_inset

.
 The difference is then coded with a 12\SpecialChar nobreakdash
bit + sign codebook for the average
 or with an 11\SpecialChar nobreakdash
bit + sign codebook if not, for a total of 14
\begin_inset space ~
\end_inset

bits 
\begin_inset Formula $\mathbf{c}_{4k+1}$
\end_inset

.
 Although the average predictor is the most useful, including the single-vector
 predictors improves the quantization of transients/onsets.
 
\end_layout

\begin_layout Standard
Because there is insufficient bitrate to adequately code 
\begin_inset Formula $\mathbf{c}_{4k}$
\end_inset

 and 
\begin_inset Formula $\mathbf{c}_{4k+2}$
\end_inset

, we only use a prediction from their neighbours.
 Vector 
\begin_inset Formula $\mathbf{c}_{4k}$
\end_inset

 is predicted from its neighbours 
\begin_inset Formula $\mathbf{c}_{4k-1}$
\end_inset

 and 
\begin_inset Formula $\mathbf{c}_{4k+1}$
\end_inset

, whereas 
\begin_inset Formula $\mathbf{c}_{4k+2}$
\end_inset

 is predicted from 
\begin_inset Formula $\mathbf{c}_{4k+1}$
\end_inset

 and 
\begin_inset Formula $\mathbf{c}_{4k+3}$
\end_inset

.
 Since there are 3
\begin_inset space ~
\end_inset

options for each vector, we have 9
\begin_inset space ~
\end_inset

possible combinations.
 By eliminating the least useful combination (
\begin_inset Formula $\mathbf{c}_{4k}=\mathbf{c}_{4k+1}=\mathbf{c}_{4k+2}$
\end_inset

), we can code the remaining ones with 3
\begin_inset space ~
\end_inset

bits.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering{
\end_layout

\end_inset


\begin_inset Graphics
	filename quantization.pdf
	width 90col%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Prediction and quantization of the cepstrum for packet
\begin_inset space ~
\end_inset


\begin_inset Formula $k$
\end_inset

.
 Vectors in green are quantized independently, vectors in blue are quantized
 with prediction, and vectors in red use prediction with no residual quantizatio
n.
 Prediction is shown by the arrows.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Prediction-and-quantization"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Training
\end_layout

\begin_layout Standard
Improved compared to the original LPCNet
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "lpcnet"
literal "false"

\end_inset

.
 Training data from NTT, varying level, varying frequency response
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "valin2017hybrid"
literal "false"

\end_inset

.
 Add noise Fig.
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Noise-injection"
plural "false"
caps "false"
noprefix "false"

\end_inset

, which is an improvement on both
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "jin2018fftnet"
literal "false"

\end_inset

 and
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "lpcnet"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering{
\end_layout

\end_inset


\begin_inset Graphics
	filename training_noise.pdf
	width 100col%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Noise injection during the training procedure, with 
\begin_inset Formula $Q$
\end_inset

 denoting 
\begin_inset Formula $\mu$
\end_inset

-law quantization and 
\begin_inset Formula $Q^{-1}$
\end_inset

 denoting conversion from 
\begin_inset Formula $\mu$
\end_inset

-law to linear.
 The prediction filter filter is given by 
\begin_inset Formula $P\left(z\right)=\sum_{k=1}^{M}a_{k}z^{-k}$
\end_inset

.
 The target excitation is computed as the difference between the clean,
 unquantized input and the noisy prediction.
 Note that the noise is added in the 
\begin_inset Formula $\mu$
\end_inset

-law domain so that its power follows that of the real excitation signal.
\begin_inset CommandInset label
LatexCommand label
name "fig:Noise-injection"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Training is first performed with unquantized features.
 When training a model for quantized features, we start with a model trained
 on unquantized features, and apply domain adaptation to quantized features.
 We have observed that better results are obtained when only the frame rate
 network is adapted, with the sample rate network weights left unchanged.
 In addition to the slightly better quality, this has the advantage of faster
 training for new quantizers and also smaller 
\end_layout

\begin_layout Section
Evaluation
\end_layout

\begin_layout Standard
Code on Github 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
url{https://github.com/mozilla/LPCNet/}
\end_layout

\end_inset

, branch, commit id 0123456789abcdef
\end_layout

\begin_layout Subsection
Complexity and Implementation
\end_layout

\begin_layout Standard
The number of weights in the sample rate network is given by
\begin_inset Formula 
\[
W=3dN_{A}^{2}+3N_{B}\left(N_{A}+N_{B}\right)+2N_{B}Q\,,
\]

\end_inset

where 
\begin_inset Formula $N_{A}$
\end_inset

 and 
\begin_inset Formula $N_{B}=16$
\end_inset

 are the sizes of the two GRUs, 
\begin_inset Formula $d$
\end_inset

 is the density of the sparse GRU, 
\begin_inset Formula $Q=256$
\end_inset

 is the number of 
\begin_inset Formula $\mu$
\end_inset

-law levels.
 Based on the subjective results in
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "lpcnet"
literal "false"

\end_inset

, we consider 
\begin_inset Formula $N_{A}=384$
\end_inset

 with 
\begin_inset Formula $d=10\%$
\end_inset

 (122 dense equivalent units) to provide a good compromise between quality
 and complexity.
 This results in 
\begin_inset Formula $W=71600\,\mathrm{weights}.$
\end_inset

 Considering that each weight is used once per sample for a multiply-add,
 the resulting complexity is 2.3
\begin_inset space ~
\end_inset

GFLOPS.
 The activation functions are based on a vectorized exponential approximation
 that contributes 0.6
\begin_inset space ~
\end_inset

GFLOPS to the complexity, for a total of 3
\begin_inset space ~
\end_inset

GFLOPS when counting the remaining operations.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
exp=15, tanh=19, sig=18, softmax=21
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Our C implementation (using AVX2/FMA) requires 20% of a 2.4
\begin_inset space ~
\end_inset

GHz Intel Broadwell core for real-time decoding.
 According to our analysis, the main performance bottleneck is the L2 cache
 bandwidth required for the matrix-vector multiplications.
 On ARM
\begin_inset Foot
status open

\begin_layout Plain Layout
Our ARM implementation has Neon optimizations for the products but not for
 the activation functions.
\end_layout

\end_inset

, real-time decoding on a 2.5
\begin_inset space ~
\end_inset

GHz Snapdragon 845 (Google Pixel
\begin_inset space ~
\end_inset

3 phone) requires X% of one core.
 
\end_layout

\begin_layout Standard
Even though the 
\end_layout

\begin_layout Standard
Compare to WaveNet-based
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "kleijn2018wavenet"
literal "false"

\end_inset

 and
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Garbacea2019"
literal "false"

\end_inset

 and to
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "klejsa2018high"
literal "false"

\end_inset

, based on SampleRNN
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "mehri2016samplernn"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
The total complexity of the encoder is around 30
\begin_inset space ~
\end_inset

MFLOPS, mostly due to the 5-best VQ search (14 MFLOPS) and the undecimated
 16
\begin_inset space ~
\end_inset

kHz pitch search (8
\begin_inset space ~
\end_inset

MFLOPS).
 Although the encoder complexity could be significantly reduced, that should
 be unnecessary in most applications since it is only 1% of the decoder
 complexity.
\end_layout

\begin_layout Subsection
Experimental Setup
\end_layout

\begin_layout Standard
The model is trained using 4
\begin_inset space ~
\end_inset

hours of speech from the NTT Multi-Lingual Speech Database for Telephonometry
 (21
\begin_inset space ~
\end_inset

languages), from which we excluded all samples from the speakers used in
 testing.
 By varying the level and frequency response, we generate 14 hours of augmented
 speech data.
 The unquantized network was trained for 120
\begin_inset space ~
\end_inset

epochs (625k
\begin_inset space ~
\end_inset

updates), with a batch size size of 64, each sequence consisting of 2400
\begin_inset space ~
\end_inset

samples (15
\begin_inset space ~
\end_inset

frames).
 Training was performed on an Nvidia GPU with Keras
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
url{https://keras.io/}
\end_layout

\end_inset


\end_layout

\end_inset

/Tensorflow
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
url{https://www.tensorflow.org/}
\end_layout

\end_inset


\end_layout

\end_inset

 using the CuDNN GRU implementation and the AMSGrad
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "reddi2018convergence"
literal "false"

\end_inset

 optimization method (Adam variant) with a step size 
\begin_inset Formula $\alpha=\frac{\alpha_{0}}{1+\delta\cdot b}$
\end_inset

 where 
\begin_inset Formula $\alpha_{0}=0.001$
\end_inset

, 
\begin_inset Formula $\delta=5\times10^{-5}$
\end_inset

, and 
\begin_inset Formula $b$
\end_inset

 is the batch number.
 For model adaptation with quantized features, we used 40
\begin_inset space ~
\end_inset

epochs (208k
\begin_inset space ~
\end_inset

updates) with 
\begin_inset Formula $\alpha_{0}=0.0001$
\end_inset

, 
\begin_inset Formula $\delta=0$
\end_inset

.
\end_layout

\begin_layout Subsection
Quality
\end_layout

\begin_layout Standard
We conducted a subjective listening test with a MUSHRA-derived methodology
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "BS1534"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
As an upper bound on the quality achievable with LPCNet at the target complexity
 (higher quality is achievable with a larger model), we include LPCNet operating
 on unquantized features.
 We also compare with Opus
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "rfc6716"
literal "false"

\end_inset

 wideband operating at 9
\begin_inset space ~
\end_inset

kb/s VBR (the lowest bitrate for which the encoder defaults to wideband)
 and to the narrowband MELP
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "mccree1996"
literal "false"

\end_inset

 vocoder.
 As low anchor, we use Speex
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "valin2007speex"
literal "false"

\end_inset

 operating as a 4
\begin_inset space ~
\end_inset

kb/s wideband vocoder (wideband quality 0).
\end_layout

\begin_layout Standard
Since the LPCNet model was trained on multiple languages, it is expected
 to also work in other languages.
 While we did not conduct tests in other languages, informal listening indicates
 that the quality obtained in French is comparable to that in English.
 
\end_layout

\begin_layout Section
Conclusions
\end_layout

\begin_layout Standard
This conclusively concludes the conclusion
\end_layout

\begin_layout Section
Acknowledgements
\end_layout

\begin_layout Standard
We'd like to acknowledge that there are acknowledgements.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "lpcnet"
options "IEEEtran"

\end_inset


\end_layout

\end_body
\end_document
